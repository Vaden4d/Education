{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "778ed5e040e1721ab23a9e08ba4639816f8e839e"
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0515806712d2ab56624a14413e2932bd4a828574"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, Sequential, load_model\nfrom keras.layers import Lambda, Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Input, Conv2D, MaxPooling2D, BatchNormalization, Concatenate, ReLU, LeakyReLU",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f39f479f521430713d5d284d768738e86a297a3e"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a6dc8976fe9bfc96348f73d609221ececfcfab74"
      },
      "cell_type": "markdown",
      "source": "## Data donwloading and preprocessing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd806c0f6c604069a244d783efd21db79730304a"
      },
      "cell_type": "code",
      "source": "metadata = pd.read_csv('../input/human-protein-atlas-image-classification/train.csv')\nmetadata = metadata.rename(columns={'Id': 'id', 'Target': 'target'})\n\nsubmission = pd.read_csv('../input/human-protein-atlas-image-classification/sample_submission.csv')\nsubmission = submission.rename(columns={'Id': 'id', 'Target': 'target'})\nsubmission = submission.astype(str)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f162deea7ac11cdf67ccbaac905fb0803fdca6cf"
      },
      "cell_type": "code",
      "source": "labels = {\n    '0' : 'Nucleoplasm', \n    '1' : 'Nuclear membrane',   \n    '2' : 'Nucleoli', \n    '3' : 'Nucleoli fibrillar center',   \n    '4' : 'Nuclear speckles',   \n    '5' : 'Nuclear bodies',   \n    '6' : 'Endoplasmic reticulum',   \n    '7' : 'Golgi apparatus',   \n    '8' : 'Peroxisomes',   \n    '9' : 'Endosomes',   \n    '10' : 'Lysosomes',   \n    '11' : 'Intermediate filaments',   \n    '12' : 'Actin filaments',   \n    '13' : 'Focal adhesion sites',  \n    '14' : 'Microtubules',   \n    '15' : 'Microtubule ends',   \n    '16' : 'Cytokinetic bridge',   \n    '17' : 'Mitotic spindle',   \n    '18' : 'Microtubule organizing center',   \n    '19' : 'Centrosome',   \n    '20' : 'Lipid droplets',   \n    '21' : 'Plasma membrane',   \n    '22' : 'Cell junctions',   \n    '23' : 'Mitochondria',   \n    '24' : 'Aggresome',   \n    '25' : 'Cytosol',   \n    '26' : 'Cytoplasmic bodies',   \n    '27' : 'Rods & rings',  \n}\n\nchannels = {\n    0: 'Microtubules',\n    1: 'Nucleus',\n    2: 'Protein',\n    3: 'Endoplasmic reticulum'\n}\n\nchannels_marker = {\n    0: 'Red',\n    1: 'Blue',\n    2: 'Green',\n    3: 'Yellow'\n}\n\ncmap_markers = {\n    0: 'Reds',\n    1: 'Blues',\n    2: 'Greens',\n    3: 'YlOrBr'\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "81d8a7de71f21a233c8833734c7926c36604410e"
      },
      "cell_type": "code",
      "source": "metadata = pd.concat([metadata, \n           pd.get_dummies(metadata.target.apply(lambda x: x.split()).apply(pd.Series).stack()).sum(level=0).sort_index(axis=1)],\n         axis=1)\nmetadata = metadata.drop(columns='target')\nmetadata = metadata.rename(columns=labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99c48e4b1d816fed58fa494de79f3c269f1e6dd2"
      },
      "cell_type": "code",
      "source": "def download_data(names, folder='train'):\n    data = []\n    for name in names:\n        full_name = os.path.join(os.getcwd(), folder, name)\n        image_red = np.array(Image.open(full_name + '_red.png'))\n        image_blue = np.array(Image.open(full_name + '_blue.png'))\n        image_green = np.array(Image.open(full_name + '_green.png'))\n        image_yellow= np.array(Image.open(full_name + '_yellow.png'))\n        image = np.dstack((image_red, image_blue, image_green, image_yellow))\n        data.append(image)\n    data = np.array(data)\n    return data\n\ndef labels_to_str(labels_tensor, mapping=labels):\n    '''labels_tensor - batch_size x 27 matrix with labels'''\n    '''result: string view of the labels'''\n    result = map(lambda x: '\\n'.join(list(map(lambda y: mapping[y], \n                                               np.where(x == 1)[0].astype(str)))), \n                 labels_tensor)\n    result = list(result)\n    return result \n\ndef generate_batch(batch_size=3, metadata=metadata):\n    n_batches = np.ceil(metadata.shape[0] / batch_size).astype(int)\n    for i in range(n_batches):\n        labels = metadata.iloc[i*(batch_size): (i+1)*batch_size].iloc[:, 1:].values\n        names = metadata.iloc[i*(batch_size): (i+1)*batch_size].id\n        yield download_data(names), labels\n        \ndef plot_samples(data):\n    samples, labels = data\n    labels_str = labels_to_str(labels)\n    n_samples = samples.shape[0]\n    n_channels = samples.shape[-1]\n    fig, axes = plt.subplots(n_samples, n_channels+1, figsize=(16, 16))\n    for i in range(n_samples):\n        for j in range(n_channels):\n            axes[i, j].set_title(labels_str[i])\n            axes[i, j].set(xlabel=channels[j], ylabel=channels_marker[j])\n            axes[i, j].imshow(samples[i, :, :, j], cmap=cmap_markers[j])\n        axes[i, n_channels].set_title('RGB image')\n        axes[i, n_channels].imshow(samples[i, :, :, :-1])\n        \ndef plot_rgb(data):\n    samples, labels = data\n    labels_str = labels_to_str(labels)\n    n_samples = samples.shape[0]\n    fig, axes = plt.subplots(1, n_samples, figsize=(16, 16))\n    for j in range(n_samples):\n        axes[j].set_title(labels_str[j])\n        axes[j].set(xlabel='RGB')\n        axes[j].imshow(samples[j, :, :, :-1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "28e6d8a0b68baae28263a12dbc203f8f310b93cd"
      },
      "cell_type": "markdown",
      "source": "## Data modeling"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "965412b71356e5f452397db7071f4847c3a687ff"
      },
      "cell_type": "code",
      "source": "images = np.load('../input/proteins128/train128.npy') \nlabels = metadata.iloc[:, 1:].values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "318db4d53082227f490b3d75763f026fdaaed01e"
      },
      "cell_type": "code",
      "source": "# some basic useless model\ndef create_model(input_shape):\n    \n    dropRate = 0.4\n    \n    init = Input(input_shape)\n    x = Lambda(lambda x: x / 255.0)(init)\n    x = BatchNormalization(axis=-1)(init)\n    x = Conv2D(8, (3, 3))(x)\n    x = ReLU()(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = Conv2D(8, (3, 3))(x)\n    x = ReLU()(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = Conv2D(16, (3, 3))(x)\n    x = ReLU()(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(dropRate)(x)\n    c1 = Conv2D(16, (3, 3), padding='same')(x)\n    c1 = ReLU()(c1)\n    c2 = Conv2D(16, (5, 5), padding='same')(x)\n    c2 = ReLU()(c2)\n    c3 = Conv2D(16, (7, 7), padding='same')(x)\n    c3 = ReLU()(c3)\n    c4 = Conv2D(16, (1, 1), padding='same')(x)\n    c4 = ReLU()(c4)\n    x = Concatenate()([c1, c2, c3, c4])\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(dropRate)(x)\n    x = Conv2D(32, (3, 3))(x)\n    x = ReLU()(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(dropRate)(x)\n    x = Conv2D(64, (3, 3))(x)\n    x = ReLU()(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(dropRate)(x)\n    x = Conv2D(128, (3, 3))(x)\n    x = ReLU()(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(dropRate)(x)\n    #x = Conv2D(256, (1, 1), activation='relu')(x)\n    #x = BatchNormalization(axis=-1)(x)\n    #x = MaxPooling2D(pool_size=(2, 2))(x)\n    #x = Dropout(0.25)(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(28)(x)\n    x = ReLU()(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = Dropout(0.1)(x)\n    x = Dense(28)(x)\n    x = Activation('sigmoid')(x)\n    \n    model = Model(init, x)\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7ba9734780a884eaf1544fb65634dd8fbfb2765"
      },
      "cell_type": "code",
      "source": "model = create_model((128, 128, 4))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa9fdae598a04e85269ace51a7f20ddefc0a731d"
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94ae087c9816a9d587e400334b77b27f09345515"
      },
      "cell_type": "code",
      "source": "from tensorflow import where, is_nan, zeros_like, ones_like, equal\ndef f1(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = where(is_nan(f1), zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef focal_loss(gamma=2.0, alpha=0.75):\n    def focal_loss_fixed(y_true, y_pred):\n        eps = 1e-4\n        y_pred = K.clip(y_pred, eps, 1.0 - eps)\n        pt_1 = where(equal(y_true, 1), y_pred, ones_like(y_pred))\n        pt_0 = where(equal(y_true, 0), y_pred, zeros_like(y_pred))\n        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.mean((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n    return focal_loss_fixed\n\ndef conv_loss():\n    def f(y_true, y_pred):\n        return 0.1 * fl(y_true, y_pred) + 0.9 * K.binary_crossentropy(y_true, y_pred)\n    return f\n\nfl = focal_loss()\nfc = conv_loss()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65a4ddeff5a40f7b71dab3639b10f2ee875e5e64"
      },
      "cell_type": "code",
      "source": "checkpoint = ModelCheckpoint('weights.h5', \n                             monitor='val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='min', \n                             save_weights_only = True)\n\n'''''reduceLROnPlato = ReduceLROnPlateau(monitor='val_loss', \n                                   factor=0.1, \n                                   patience=3, \n                                   verbose=1, \n                                   mode='auto', \n                                   epsilon=0.0001)'''''\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=10)\ncallbacks_list = [checkpoint, early]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02fac5ba53d945f3c5419757b8d0ca9c0e3b3a27"
      },
      "cell_type": "code",
      "source": "epochs = 20\nbatch_size = 128",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ed24665a8d9ec4d7e69c29f01fbed30edf16d0a"
      },
      "cell_type": "code",
      "source": "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.2, random_state=52)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e46fe0fc0a619d56e72f005384b0c35d1b99166"
      },
      "cell_type": "code",
      "source": "model.compile(loss=['binary_crossentropy'],\n            optimizer=Adam(lr=1e-4),\n            metrics=[fl, 'acc'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd5620bad254544175cbc8093fe1272b6cc70444"
      },
      "cell_type": "code",
      "source": "model.fit(images_train, \n          labels_train, \n          batch_size, \n          epochs, \n          callbacks=callbacks_list, \n          validation_data=(images_test, labels_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "789b88654b0213f924a6417054495b3aedded653"
      },
      "cell_type": "markdown",
      "source": "## Prepredicting"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d685f4dc5284e9f0090357005ee94bdbd81cb7a1"
      },
      "cell_type": "code",
      "source": "pred_train = model.predict(images_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee82fcddbc2121d80cebdc260ebd1e2b1a43ace9"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score\n\nthresholds = np.linspace(0, 1, 200)\nth = []\nscore = 0.0\nbest_threshold=0.0\nbest_val = 0.0\nfor i in range(28):\n    best_threshold=0.0\n    best_val = 0.0\n    for threshold in thresholds:\n        score = f1_score(labels_train[:, i], pred_train[:, i] > threshold, average='macro')\n        if score > best_val:\n            best_threshold = threshold\n            best_val = score\n    th.append(best_threshold)\nth = np.array(th)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1899eafcb95d3b95e0c6714f30eb313218773e7"
      },
      "cell_type": "code",
      "source": "th",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2f9d3e6139e8ac858ec7330434d93cc2cd4a091c"
      },
      "cell_type": "code",
      "source": "f1_score(labels_test, model.predict(images_test) > np.repeat([th], labels_test.shape[0], axis=0), average='macro')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "041701b996f7051861032bd98b68c90775a846e1"
      },
      "cell_type": "code",
      "source": "test = np.load('../input/proteins128/test128.npy')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4298480389ea5755f453ce46c5c74f8ec26fab89"
      },
      "cell_type": "code",
      "source": "def create_submission(model, test_images, test_csv, thresholds):\n    for i, image in enumerate(test_images):\n        y_pred = model.predict(np.expand_dims(image, axis=0)) > thresholds\n        test_csv.at[i, 'Predicted'] = ' '.join(np.where(y_pred[0])[0].astype(str))\n    return test_csv",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9dea00379395a866c03410daba073fcc4d138b9"
      },
      "cell_type": "code",
      "source": "create_submission(model, test, submission, th).to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35988ed8eddd91b680c3747e5d2d151f5ed9cbe0"
      },
      "cell_type": "code",
      "source": "submission",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "edc2998702600e2c95fd8003721f91067402a557"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}